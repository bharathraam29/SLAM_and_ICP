{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c310efd-4b05-44bd-a4cc-15e8b7e32041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575b1653-64a4-4159-8ed8-28dc7ce79d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"/home/bradhakrishnan/ECE276A_PR2/code\")\n",
    "sys.path.insert(0, \"/home/bradhakrishnan/ECE276A_PR2/code/icp_warm_up/\")\n",
    "\n",
    "data_base_path= \"/home/bradhakrishnan/ECE276A_PR2/code/icp_warm_up/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718b438b-a491-48f2-8442-caf0f311729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "# import icp_warm_up.test_icp as icp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f6b87d-0814-4f76-9a4c-86328fea8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import read_canonical_model, load_pc, visualize_icp_result\n",
    "\n",
    "obj_name = 'drill' # drill or liq_container\n",
    "num_pc = 4 # number of point clouds\n",
    "\n",
    "source_pc = read_canonical_model(obj_name, base_path=data_base_path)\n",
    "\n",
    "for i in range(num_pc):\n",
    "    target_pc = load_pc(obj_name, i, base_path=data_base_path)\n",
    "    \n",
    "    # estimated_pose, you need to estimate the pose with ICP\n",
    "    pose = np.eye(4)\n",
    "    \n",
    "    # # visualize the estimated result\n",
    "    # visualize_icp_result(source_pc, target_pc, pose)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34cef955-8df8-4ba0-b036-a4f37e1d9bd7",
   "metadata": {},
   "source": [
    "target_pc : Doesn't move\n",
    "Souce_pc: moves\n",
    "\n",
    "# We are assuming movement only around Z-axis => we assume our rotation matrix to have only yaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64de7355-b634-4ba4-8ff3-e0fa527d195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_pose(init_R, init_P):\n",
    "    init_T= np.zeros([4,4])\n",
    "    init_T[:3,:3]= init_R\n",
    "    init_T[:, -1]= np.hstack((init_P, np.array([1])))\n",
    "    return init_T\n",
    "\n",
    "def get_R_and_P(T):\n",
    "    return T[:3,:3], T[:-1,-1]\n",
    "\n",
    "def get_corres_points(target_pc_moved, source_pc):\n",
    "    kn_obj=NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(target_pc_moved)\n",
    "    dist, idx= kn_obj.kneighbors(source_pc)\n",
    "    return dist.flatten().sum(), idx.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd8195d2-3f62-4c0c-ad83-5d5891cdbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAW_VALUE ::  2.0943951023931953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 338.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import transforms3d as t3d\n",
    "from tqdm import tqdm\n",
    "sampled_target_pc= target_pc[::10]\n",
    "sampled_source_pc= source_pc[::10]\n",
    "number_of_yaw_splits= 3\n",
    "yaw_split= 2*np.pi/number_of_yaw_splits\n",
    "max_iters= 1000\n",
    "\n",
    "\n",
    "for ii in range(1, number_of_yaw_splits+1):\n",
    "    yaw_val= yaw_split*ii\n",
    "    print(\"YAW_VALUE :: \", yaw_val)\n",
    "    init_R= t3d.euler.euler2mat(0,0, yaw_val)\n",
    "    target_centroid= target_pc.mean(axis=0)\n",
    "    source_centroid= source_pc.mean(axis=0)\n",
    "    init_P= target_centroid- source_centroid\n",
    "    init_T = get_pose(init_R, init_P)\n",
    "    accumulated_T= init_T\n",
    "    prev_dist= 0\n",
    "    curr_R, curr_p= get_R_and_P(init_T)\n",
    "    moved_pc= np.matmul(curr_R,sampled_target_pc.T).T+curr_p\n",
    "    distace_res, matched_idxs= get_corres_points(moved_pc,sampled_source_pc)\n",
    "    dist_between_corresponding_pc_pts= np.linalg.norm(sampled_source_pc-moved_pc[matched_idxs],axis=1)\n",
    "    #filter points that are too far away\n",
    "    filter_dist_threshold= 0.5\n",
    "    filtered_idx = np.where(dist_between_corresponding_pc_pts < filter_dist_threshold)\n",
    "    sampled_source_pc=sampled_source_pc[filtered_idx]\n",
    "    moved_pc=moved_pc[matched_idxs][filtered_idx]\n",
    "    for itr in tqdm(range(max_iters)):\n",
    "        distace_res, matched_idxs= get_corres_points(moved_pc,sampled_source_pc)\n",
    "        moved_centroid= moved_pc.mean(axis=0)\n",
    "        sampled_source_centroid= sampled_source_pc.mean(axis=0)\n",
    "        centered_sampled_source_pc = sampled_source_pc - sampled_source_centroid\n",
    "        centered_sampled_moved_pc = moved_pc - moved_centroid\n",
    "        Q = np.matmul(centered_sampled_source_pc.transpose(), centered_sampled_moved_pc[matched_idxs])\n",
    "        U, S, Vt = np.linalg.svd(Q, full_matrices=True)\n",
    "        curr_R= np.matmul(U, Vt)\n",
    "        curr_p = sampled_source_centroid - np.matmul(curr_R, moved_centroid.T).T\n",
    "    \n",
    "        new_T= get_pose(curr_R, curr_p)\n",
    "        accumulated_T= np.matmul(new_T, accumulated_T)\n",
    "        moved_pc= np.matmul(curr_R,centered_sampled_moved_pc.T).T+curr_p\n",
    "        \n",
    "        if np.abs(distace_res- prev_dist) < 1e-6:\n",
    "            print(accumulated_T , distace_res)\n",
    "            break\n",
    "        prev_dist= distace_res\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a274945-01e1-4277-8682-d5b72f5d2957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "visualize_icp_result(source_pc, target_pc, pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a49e043-e50c-41bc-bade-82a5be814b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72455464, -0.56011031,  0.40161799,  1.15322851],\n",
       "       [ 0.19471972,  0.72533391,  0.660284  , -0.38832314],\n",
       "       [ 0.66113902,  0.4002089 , -0.63460857, -1.60961169],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cda943-61fc-47fe-96ad-de74561d3166",
   "metadata": {},
   "source": [
    "# ICP set up \n",
    "1. Take target and move as per our R and P ; i.e R*target_pc+P\n",
    "2. Build correspondece array\n",
    "3. Now do kabsch stuff, find Q ie; correlation\n",
    "4. SVD => get new P and R\n",
    "5. Somehow accumulate the pose estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab66a21-98aa-42db-9396-956cd276bf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "426a278b-a271-42ac-857c-099b480becec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1169, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a98d5e9-4a1e-4bfa-8b71-2e48ea7d97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcc1f725-260d-4b23-988b-c0cd32087f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.47122421e-15, -1.70370445e-15, -3.67093210e-16],\n",
       "       [-2.47122421e-15, -1.70370445e-15, -3.67093210e-16],\n",
       "       [-2.47122421e-15, -1.70370445e-15, -3.67093210e-16],\n",
       "       ...,\n",
       "       [-2.47122421e-15, -1.70370445e-15, -3.67093210e-16],\n",
       "       [-2.47122421e-15, -1.70370445e-15, -3.67093210e-16],\n",
       "       [-2.47122421e-15, -1.70370445e-15, -3.67093210e-16]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(curr_R, centered_sampled_moved_pc.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edc5552-8062-461c-a773-f01c73d11a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.34106354e-29,  2.99767144e-29,  4.33873498e-30],\n",
       "       [-1.06496222e-29,  1.81438008e-29,  2.85962078e-30],\n",
       "       [ 1.57772181e-30,  9.46633086e-30,  1.18329136e-30]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d34a45a-ebc6-4219-9416-d07f1d79bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1169, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73fed9-8dfe-42a9-884d-2bf08cff5a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84f3f28-c514-4662-bc22-c5da3313a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching point clouds with ICP using discretized yaws\n",
      "Current yaw guess in rads: 0.0\n",
      "Dist::  58.986466887691705\n",
      "[[ 0.54593535  0.76781114  0.33529189 -0.34407122]\n",
      " [-0.65175371  0.64066889 -0.40590699  0.39594481]\n",
      " [-0.52647099  0.00307124  0.85018755  0.26745378]\n",
      " [ 0.          0.          0.          1.        ]] 30.823011686799294\n",
      "Current yaw guess in rads: 1.5707963267948966\n",
      "Dist::  56.26765557558488\n",
      "[[-0.47431601 -0.86513063 -0.16301325  0.29603772]\n",
      " [ 0.69615097 -0.48193048  0.53208725 -0.42835456]\n",
      " [-0.53888603  0.13889567  0.83084887  0.2733437 ]\n",
      " [ 0.          0.          0.          1.        ]] 29.150709749461345\n",
      "Current yaw guess in rads: 3.141592653589793\n",
      "Dist::  57.194240123289525\n",
      "[[-0.5631342  -0.74414436 -0.35934529  0.35531846]\n",
      " [ 0.61923064 -0.66794482  0.41279913 -0.3777121 ]\n",
      " [-0.54720497  0.00994369  0.83693957  0.28214317]\n",
      " [ 0.          0.          0.          1.        ]] 30.479983483035273\n",
      "Current yaw guess in rads: 4.71238898038469\n",
      "Dist::  52.41570260537423\n",
      "[[ 0.46917134  0.85968029  0.20205951 -0.29495304]\n",
      " [-0.70353383  0.50215055 -0.5028767   0.43165094]\n",
      " [-0.53377749  0.09377964  0.84040881  0.27308202]\n",
      " [ 0.          0.          0.          1.        ]] 26.8683687330237\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import time \n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as a3\n",
    "import transforms3d\n",
    "from transforms3d.euler import euler2mat, mat2euler, quat2euler\n",
    "import open3d as o3d\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from utils import read_canonical_model, load_pc, visualize_icp_result\n",
    "import numpy.ma as ma\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "def createPoseMatrix(R, p):\n",
    "  p = np.atleast_2d(p).transpose()\n",
    "  result = np.hstack((R, p))\n",
    "  result = np.vstack((result, np.array([0,0,0,1])))\n",
    "  return result\n",
    "\n",
    "def trajectoryFromPose(pose):\n",
    "    R = pose[:3, :3]\n",
    "    x, y, z = mat2euler(R)\n",
    "    p = pose[:2, 3]\n",
    "    return np.hstack((p, z))\n",
    "\n",
    "def transformVectorsByR(R, x):\n",
    "    return np.transpose(np.matmul(R, x.transpose()))\n",
    "\n",
    "\n",
    "def findPointCloudCentroid(pc):\n",
    "    pointsCount = np.shape(pc)[0]\n",
    "    sum = np.sum(pc, axis=0)\n",
    "    return sum / pointsCount\n",
    "\n",
    "def buildCorrespondenceArray(m, z, R, p):\n",
    "    z = transformVectorsByR(R, z) + p\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(z)\n",
    "    distances, indicies = nbrs.kneighbors(m) #indicies returns for each point in m, it gives the index of z that is the closest point\n",
    "    distances = distances.flatten()\n",
    "    indicies = indicies.flatten()\n",
    "    return indicies, np.sum(distances) #return the correspondences and the summed error of all the pairs\n",
    "\n",
    "\n",
    "def ICP(poseInit, source_pc, target_pc, maxIterations, downSample, visualize=False, distanceNearest = 0.2):\n",
    "\n",
    "    R = poseInit[:3, :3]\n",
    "    p = poseInit[:3, 3] #initialize R and p with guess pose\n",
    "\n",
    "    source_pc_ = source_pc[0:-1:downSample] \n",
    "    target_pc_ = target_pc[0:-1:downSample] #downsample parameter takes subset of pointcloud to make icp faster\n",
    "\n",
    "    target_pc_ = transformVectorsByR(R, target_pc_) + p #orient target to initial guess pose\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    distances = 0\n",
    "    previousDistances = 0\n",
    "    resultPose = poseInit\n",
    "\n",
    "    correspondence, distances = buildCorrespondenceArray(source_pc_, target_pc_, np.identity(3), np.zeros(3)) #here we pass over identity pose because the point cloud has already been moved closer from the previous iteration's R and p\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    print(\"Dist:: \", distances)\n",
    "    normsNew = np.linalg.norm(source_pc_ - target_pc_[correspondence], axis=1) #get distances between associated points\n",
    "    indexPointsCloseEnough = np.where(normsNew < distanceNearest) #get index of point pairs that are close to each other\n",
    "\n",
    "    source_pc_ = source_pc_[indexPointsCloseEnough] \n",
    "    target_pc_ = target_pc_[correspondence][indexPointsCloseEnough]\n",
    "    #discard points that are far away from the target points since they probably don't actually have an association\n",
    "\n",
    "    for i in range(maxIterations):\n",
    "        \n",
    "        correspondence, distances = buildCorrespondenceArray(source_pc_, target_pc_, np.identity(3), np.zeros(3)) #here we pass over identity pose because the point cloud has already been moved closer from the previous iteration's R and p\n",
    "        \n",
    "        if visualize == True:\n",
    "            visualize_icp_result(source_pc_, target_pc_, np.identity(4), np.identity(4)) #for debug\n",
    "\n",
    "\n",
    "        #print(\"For ICP iteration \" + str(i) + \", the summed error between target and source is: \" + str(distances))\n",
    "\n",
    "        #execute Kabsch algorithm with found correspondences and no-correspondence points removed from both point clouds\n",
    "\n",
    "        centerSource = findPointCloudCentroid(source_pc_)\n",
    "        centerTarget = findPointCloudCentroid(target_pc_)\n",
    "\n",
    "        centeredSourcePC = source_pc_ - centerSource\n",
    "        centeredTargetPC = target_pc_ - centerTarget\n",
    "\n",
    "        Q = np.matmul(centeredSourcePC.transpose(), centeredTargetPC[correspondence])\n",
    "\n",
    "        U, S, Vh = np.linalg.svd(Q, full_matrices=True)\n",
    "        R = np.matmul(U, Vh)\n",
    "        p = centerSource - transformVectorsByR(R, centerTarget)\n",
    "\n",
    "        iterationPose = createPoseMatrix(R, p)\n",
    "        resultPose = np.matmul(iterationPose, resultPose) #multiply result pose with currently found iteration pose to accumulate poses\n",
    "        target_pc_ = transformVectorsByR(R, target_pc_) + p #move target incrementally closer to source\n",
    "\n",
    "        if np.abs(distances - previousDistances) < 0.0000000001: #if the change in error is not significant, stop algorithm\n",
    "            finalDistance = distances #store the final summed norm error between the point clouds\n",
    "            break\n",
    "        \n",
    "        previousDistances = distances\n",
    "    print(resultPose, finalDistance)\n",
    "    return resultPose, finalDistance #return both the estimated relative pose and converged summed error of the matched point clouds\n",
    "\n",
    "\n",
    "def visualize_icp_result(source_pc, target_pc, source_pose, target_pose):\n",
    "  '''\n",
    "  Visualize the result of ICP\n",
    "  source_pc: numpy array, (N, 3)\n",
    "  target_pc: numpy array, (N, 3)\n",
    "  pose: SE(4) numpy array, (4, 4)\n",
    "  \n",
    "  '''\n",
    "  source_pcd = o3d.geometry.PointCloud()\n",
    "  source_pcd.points = o3d.utility.Vector3dVector(source_pc.reshape(-1, 3))\n",
    "  source_pcd.paint_uniform_color([0, 0, 1])\n",
    "\n",
    "  source_pcd.transform(source_pose)\n",
    "\n",
    "  target_pcd = o3d.geometry.PointCloud()\n",
    "  #target_pcd.points = o3d.utility.Vector3dVector((np.matmul(target_pc,R) + p).reshape(-1, 3))\n",
    "  target_pcd.points = o3d.utility.Vector3dVector(target_pc.reshape(-1, 3))\n",
    "  target_pcd.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "  target_pcd.transform(target_pose)\n",
    "\n",
    "  o3d.visualization.draw_geometries([source_pcd, target_pcd])\n",
    "\n",
    "  \n",
    "numberOfDiscreteYaws = int(4) #number of yaw amounts to test for best initial pose guess from 0 to 2*pi\n",
    "incrementalYaw = (2 * np.pi) / numberOfDiscreteYaws\n",
    "\n",
    "errors = np.empty(1)\n",
    "poses = []\n",
    "\n",
    "print(\"Matching point clouds with ICP using discretized yaws\")\n",
    "\n",
    "for yawGuess in range(numberOfDiscreteYaws):\n",
    "\n",
    "    print(\"Current yaw guess in rads: \" + str(yawGuess * incrementalYaw))\n",
    "\n",
    "    RInit = transforms3d.euler.euler2mat(0,0,yawGuess * incrementalYaw) #create rotation matrix based on yaw guess\n",
    "    centerSourceInit = findPointCloudCentroid(source_pc)\n",
    "    centerTargetInit = findPointCloudCentroid(transformVectorsByR(RInit, target_pc)) #find the centroid AFTER rotation\n",
    "    pInit = centerSourceInit - centerTargetInit #a good position estimate is the difference between the two centroids\n",
    "    poseInit = createPoseMatrix(RInit, pInit)\n",
    "    poseICP, summedError = ICP(poseInit, source_pc, target_pc, 1000, 10) #run ICP with max iterations of 1000 and downsample factor of 10\n",
    "    errors = np.append(errors, summedError) #track errors for each yaw increment\n",
    "    poses.append(poseICP) #track associated pose with error\n",
    "    \n",
    "\n",
    "# errors = errors[1:] #remove first element\n",
    "# visualize_icp_result(source_pc, target_pc, np.identity(4), poses[np.argmin(errors)]) #show ICP pose with the minimal error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f2f22-c105-4339-a4e8-6d23219bb551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
